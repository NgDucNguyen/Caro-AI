{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Báo cáo Project\n",
    "Lớp TTNT-162297, Nhóm G22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Thông tin chung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thành viên\n",
    "- Vũ Hải Minh 20235166 - Nhóm trưởng\n",
    "- Nguyễn Đức Nguyên 202416305\n",
    "- Nguyễn Trí Dũng 20235053\n",
    "- Nguyễn Đăng Minh 202416567"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lịch thực hiện\n",
    "- W02: Đăng ký nhóm \n",
    "- W03: Đề xuất project (28/9)\n",
    "- W08: Báo cáo tiến độ giữa kỳ (1/11)\n",
    "- W15: Hoàn thành và gửi báo cáo project (20/12)\n",
    "- W16-18: Trình bày project, Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Đề xuất project (W3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài toán : Ứng dụng thuật toán Minimax trong trò chơi cờ Caro\n",
    "\n",
    "Cờ Caro (Gomoku hay “Năm quân liên tiếp”) là một trò chơi bàn cờ có nguồn gốc từ Nhật Bản, phổ biến trên thế giới và đặc biệt quen thuộc ở Việt Nam. Trò chơi thường được chơi trên bàn 15x15 hoặc 19x19, với hai người chơi lần lượt đặt quân X và O. Mục tiêu của mỗi người là tạo được một chuỗi 5 quân liên tiếp theo hàng ngang, dọc hoặc chéo.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phương pháp\n",
    "- Trò chơi Caro ứng dụng thuật toán Minimax kết hợp cắt tỉa Alpha-Beta để tìm ra nước đi tối ưu cho máy. \n",
    "- Minimax hoạt động bằng cách giả định người chơi luôn chọn nước đi tốt nhất cho mình, từ đó máy sẽ tính toán phản ứng tối ưu. \n",
    "- Để giảm số lượng trạng thái phải duyệt, Alpha-Beta pruning được dùng nhằm loại bỏ các nhánh không cần thiết.\n",
    "- Ngoài ra, một hàm đánh giá heuristic được xây dựng để ước lượng thế cờ ở các độ sâu tìm kiếm, giúp AI vừa nhanh vừa chính xác hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phân công\n",
    "- Hải Minh: Heuristic & Luật chơi nâng cao\n",
    "- Nguyên: Thuật toán Minimax + Alpha-Beta\n",
    "- Dũng: Giao diện & Hiển thị\n",
    "- Đăng Minh:  Quản lý bàn cờ & Logic trận đấu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tiến độ giữa kỳ (W8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chương trình\n",
    "- Cấu trúc chương trình:\n",
    "  - venv : Môi trường ảo\n",
    "  - assets: phông chữ, hình ảnh, icon,..\n",
    "  - src: backend và frontend\n",
    "     - backend: \n",
    "        - features.py: Tính năng và quản lý bộ điều khiển\n",
    "        - game.py: Tệp chứa logic cơ bản của luật chơi\n",
    "        - minimax.py: Tệp chứa thuật toán để máy tính tìm ra nước đi thông minh nhất\n",
    "     - frontend:\n",
    "        - launcher.py: Chọn chế độ chơi của bàn cờ trước khi vào\n",
    "        - uiInGame.py: Là giao diện trò chơi\n",
    "- Cơ chế AI (Thuật toán Minimax): Áp dụng phương pháp Suy diễn đối kháng (Minimax) với kỹ thuật tối ưu hóa Cắt tỉa Alpha-Beta (Alpha-Beta Pruning).\n",
    "\n",
    "   - Giai đoạn 1: Hàm evaluate() (trong game.py) được dùng để gán điểm số cho một trạng thái bàn cờ cụ thể (ví dụ: AI thắng: +1, Người   thắng:-1, Hòa/Chưa kết thúc: 0).\n",
    "   - Giai đoạn 2: Tìm kiếm đệ quy (Search)\n",
    "       Hàm minimax() (trong minimax.py) \"nhìn trước\" tất cả các kịch bản có thể xảy ra.\n",
    "       Nó giả định rằng người chơi (X) sẽ luôn chọn nước đi có lợi nhất cho họ (tối thiểu hóa điểm số - min).\n",
    "AI (O) sẽ tìm và chọn nước đi mang lại điểm số cao nhất (tối đa hóa điểm số - max) sau khi đã xét đến mọi phản ứng tối ưu của đối thủ.\n",
    "   - Kết quả: Hàm best_move() trả về vị trí ô cờ đảm bảo kết quả tốt nhất (thắng, hoặc hòa nếu không thể thắng) cho AI.\n",
    "game.py\n",
    "\n",
    "- Một số hình ảnh của chương trình: https://drive.google.com/drive/folders/19kmdGT53J0pRqmt7T40YNp6-LZPfQtjq?usp=sharing\n",
    "- Link github: https://github.com/NgDucNguyen/Caro-AI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phân tích kết quả, vấn đề gặp phải\n",
    "- Phân tích kết quả:\n",
    "  - Triển khai thành công thuật toán Minimax (Alpha-Beta)\n",
    "  - Tạo ra AI đối kháng bất bại với bàn cờ 3x3\n",
    "  - AI có thể đối phó với nhiều lối đánh khác nhau của người chơi\n",
    "\n",
    "- Vấn đề gặp phải:\n",
    "  - Chế độ chơi chưa đa dạng\n",
    "  - Kích thước bàn cờ cố định 3x3\n",
    "\n",
    "- Dự kiến đến cuối kì:\n",
    "  - Mở rộng lối chơi, bổ sung luật chơi mới\n",
    "  - Đa dạng kích thước bàn cờ\n",
    "  - Tùy chọn độ sâu cho thuật toán, bật tắt Alpha-Beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cập nhật kết quả cuối kỳ (W15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi tiết phương pháp, dữ liệu \n",
    "#### **1. Dữ liệu đầu vào và biểu diễn trạng thái**\n",
    "##### 1.1. Tập dữ liệu chính là trạng thái bàn cờ tùy thuộc vào người chơi thiết lập\n",
    "- Bàn cờ được biểu diễn bằng mảng 2 chiều:\n",
    "  + **board = [\" \"] * (BOARD_N * BOARD_N)**\n",
    "  + Mỗi phần tử là **\" \"** (trống), **\"X\"** hoặc **\"O\"**\n",
    "- Kích thước và độ dài thắng có thể thay đổi:\n",
    "  + **BOARD_N**: kích thước N×N (ví dụ 3, 5, 7, …)\n",
    "  + **WIN_LENGTH**: số quân liên tiếp để thắng (ví dụ 3, 4, 5, …)\n",
    "- Thiết lập tham số:\n",
    "  + Khi bắt đầu game, **features.init_board(size, winlen)** sẽ khởi tạo lại board và đồng bộ tham số qua **game.set_board_params(BOARD_N, WIN_LENGTH)**\n",
    "\n",
    "##### 1.2. Lịch sử dữ liệu trong ván:\n",
    "- **move_history**: lưu lại các nước đi theo thứ tự để phục vụ Undo\n",
    "- **scores**: thống kê tổng số ván thắng của X/O và hòa (D)\n",
    "\n",
    "#### **2. Luật trò chơi và điều kiện kết thúc**\n",
    "##### 2.1. Hệ thống sẽ kiểm tra kết thúc game dựa trên 2 điều kiện\n",
    "- Thắng: + Duyệt mọi ô và kiểm tra 4 hướng\n",
    "         + Nếu tồn tại 1 đoạn > **WIN_LENGTH** -> thắng\n",
    "- Hòa: Nếu không còn ô trống trên bàn cờ\n",
    "\n",
    "##### 2.2. Ngoài ra, để hiển thị trực quan, hệ thống tìm các ô tạo thành chuỗi thắng: \n",
    "   + **get_winning_cells(board, mark)**: trả về danh sách index để highlight trên UI.\n",
    "\n",
    "#### **3. Phương pháp : Minimax + Alph-Beta + Heuristic**\n",
    "##### Thuật toán giúp AI không duyệt toàn bộ bàn cờ, mà dùng các kĩ thuật để giảm bớt số Node phải duyệt giúp nhanh hơn mà vẫn chính xác\n",
    "\n",
    "##### **3.1. Thuật toán Minimax + Alpha-Beta**\n",
    "\n",
    "AI dùng Minimax để giả lập \"2 bên đều chơi tối ưu\"\n",
    "  + AI là maximizing player\n",
    "  + Người chơi là minimizing player\n",
    "\n",
    "Alpha-Beta pruning:\n",
    "  + Dùng **alpha** và **beta** để cắt nhánh chắc chắn không ảnh hưởng kết quả tối ưu\n",
    "\n",
    "\n",
    "##### **3.2 Heuristic mở hai đầu ( đánh giá trạng thía chưa kết thúc )**:\n",
    "Khi đạt giới hạn depth mà game chưa kết thúc, AI dùng heuristic_score để ước lượng \n",
    "\n",
    "Ý tưởng: \n",
    "  - Duyệt mọi đoạn dài **WIN_LENGTH** theo 4 hướng.\n",
    "  - Nếu đoạn đó chứa cả AI và PLAYER → bỏ (bị chặn hai phía về mặt sở hữu).\n",
    "  - Đếm số quân:\n",
    "    + **ai_cnt, pl_cnt**\n",
    "  - Tính **open ends** (mức “mở” hai đầu):\n",
    "\n",
    "     + Xét ô trước đoạn và sau đoạn:\n",
    "\n",
    "        + nếu ngoài bàn hoặc bị chiếm → bị block\n",
    "\n",
    "        + open_ends ∈ {0,1,2}\n",
    "\n",
    "Chấm điểm:\n",
    " - Nếu chỉ AI xuất hiện: cộng điểm\n",
    "    + #### **score += (10 ** ai_cnt) * open_ends**\n",
    " - Nếu chỉ PLAYER: trừ điểm\n",
    "    + #### **score -= (10 ** pl_cnt) * open_ends**\n",
    " - Nếu có chuỗi thắng chắc:\n",
    "   + AI đủ **WIN_LENGTH** → trả về **10_000_000**\n",
    "   + Player đủ **WIN_LENGTH** → trả về **-10_000_000**\n",
    "\n",
    "Ý nghĩa:\n",
    "\n",
    "  - Chuỗi càng dài càng nguy hiểm/tiềm năng (10^cnt).\n",
    "\n",
    "   - Chuỗi mở 2 đầu được ưu tiên mạnh hơn chuỗi bị chặn.\n",
    "\n",
    "\n",
    "##### **3.3. Candidate Moves(giảm số nước phải xét)**\n",
    "Thay vì xét tất cả ô trống, AI chỉ xét các ô “có ý nghĩa” nằm gần những quân đã đánh:\n",
    "\n",
    "  - Lấy danh sách ô đã có quân: **occupied**\n",
    "  - Nếu bàn trống → đánh giữa.\n",
    "  - Nếu không trống:\n",
    "    + Lấy **radius = max(1, WIN_LENGTH - 2)**\n",
    "    + Sinh các ô trống trong vùng lân cận quanh mỗi ô đã đánh\n",
    "\n",
    "##### **3.4. Quy trình ra quyết định nước đi của AI (Best Move)**\n",
    "AI chọn nước đi theo thứ tự ưu tiên:\n",
    "  - **Thắng ngay**: thử đặt AI vào từng candidate move → nếu winner → chọn luôn.\n",
    "  - **Chặn thua ngay**: thử đặt PLAYER → nếu winner → block ngay.\n",
    "  - Nếu không có tình huống tức thời:\n",
    "     + Chạy minimax (alpha-beta hoặc minimax thường tùy mode)\n",
    "     + Chọn nước có điểm cao nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chương trình\n",
    "\n",
    "#### **1. Chức năng chính**\n",
    "- Cho phép chơi **Người vs Người (PVP)** và **Người vs Máy (PVE)**.\n",
    "- Hỗ trợ bàn cờ **N×N** với độ dài thắng **WIN_LENGTH** tùy chọn.\n",
    "- Cho phép lựa chọn:\n",
    "  + Thuật toán AI (Minimax thường / Minimax + Alpha-Beta / Không AI)\n",
    "  + Độ sâu tìm kiếm (depth)\n",
    "  + Người chơi đi trước (X hoặc O).\n",
    "- Cung cấp các thao tác:\n",
    "  + Bắt đầu ván mới\n",
    "  + Hoàn tác nước đi (Undo)\n",
    "- Hiển thị:\n",
    "  + Trạng thái ván đấu\n",
    "  + Điểm số\n",
    "  + Thời gian suy nghĩ của AI cho từng nước đi.\n",
    "\n",
    "#### **2. Kiến trúc chương trình**\n",
    "**Chương trình được chia thành 2 phần chính:**\n",
    "- **Frontend**:  \n",
    "  + Giao diện HTML (Launcher) cho phép cấu hình trò chơi.\n",
    "  + Giao diện Pygame hiển thị bàn cờ, bắt sự kiện người chơi và hiển thị kết quả.\n",
    "- **Backend**:\n",
    "  + Module xử lý luật chơi và trạng thái bàn cờ.\n",
    "  + Module AI sử dụng Minimax và Heuristic để chọn nước đi tối ưu.\n",
    "\n",
    "**Launcher → UI → Backend → AI → UI**\n",
    "\n",
    "#### **3. Luồng hoạt động của chương trình**\n",
    "**Luồng khi chơi Người với Máy:**\n",
    "1. Người chơi click vào ô trên bàn cờ.\n",
    "2. Chương trình cập nhật trạng thái và kiểm tra thắng/hòa.\n",
    "3. Nếu ván chưa kết thúc, đến lượt AI.\n",
    "4. AI gọi Minimax để chọn nước đi tốt nhất.\n",
    "5. Kết quả được cập nhật và hiển thị lên giao diện.\n",
    "6. Ván đấu tiếp tục cho đến khi kết thúc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phân tích, đánh giá kết quả\n",
    "\n",
    "### **Kết quả**:\n",
    "- Hình ảnh chạy chương trình: \n",
    "- Link github: \n",
    "\n",
    "### **Phân tích, đánh giá**\n",
    "#### **1. So sánh hiệu năng giữ Minimax có và không có Alpha-Beta**\n",
    "Hình dưới trình bày kết quả so sánh thời gian suy nghĩ trung bình của AI khi sử dụng **Minimax** có **Alpha-Beta pruning** và **không có Alpha-Beta** ở các độ sâu tìm kiếm khác nhau\n",
    "\n",
    "Hình\n",
    "\n",
    "Từ kết quả thực nghiệm có thể nhận thấy sựu khác biệt rõ rệt ở giữa hai phương pháp:\n",
    "- Ở **depth nhỏ** (depth 1, depth 3):\n",
    " + Thời gian chạy của hai phương pháp không chênh lệch nhiều.\n",
    " + Do cây tìm kiếm còn nông, số trạng thái cần duyệt chưa lớn nên lợi ích của Alpha-Beta chưa thể hiện rõ.\n",
    "- Khi **depth tăng** (depth 5, depth 7):\n",
    "  + Minimax **không sử dụng Alpha-Beta** có thời gian chạy tăng rất nhanh, lên đến hàng trăm mili-giây.\n",
    "  + Trong khi đó, Minimax **có Alpha-Beta** vẫn duy trì thời gian xử lý rất thấp và tăng chậm.\n",
    "-> Điều này cho thấy **Alpha-Beta pruning** giúp cắt bỏ hiệu quả các nhánh không cần thiết, từ đó giảm đáng kể số trạng thái phải đánh giá trong cây Minimax.\n",
    "\n",
    "#### **2. Ảnh hưởng của độ sâu tìm kiếm (Depth)**\n",
    "Kết quả từ bảng so sánh cũng phản ánh rõ ảnh hưởng của tham số depth:\n",
    "- **Depth càng lớn: **\n",
    "   + Chất lượng quyết định của AI càng tốt do nhìn trước được nhiều nước hơn.\n",
    "   + Tuy nhiên, chi phí tính toán tăng theo cấp số nhân nếu không có kỹ thuật tối ưu.\n",
    "- Với Minimax thường, việc tăng depth nhanh chóng làm thời gian chạy trở nên không thực tế.\n",
    "- Với Alpha-Beta pruning, AI có thể tăng depth mà vẫn đảm bảo thời gian phản hồi chấp nhận được.\n",
    "-> Do đó, việc giới hạn depth kết hợp Alpha-Beta là cần thiết để cân bằng giữa **độ chính xác và hiệu năng**.\n",
    "\n",
    "#### **3. Đánh giá vai trò của Heuristic**\n",
    "Trong các cấu hình có giới hạn độ sâu, heuristic đóng vai trò quan trọng trong việc đánh giá các trạng thái chưa kết thúc:\n",
    "- Heuristic dựa trên số quân liên tiếp và số đầu mở giúp AI:\n",
    "    + Ưu tiên các chuỗi tấn công tiềm năng.\n",
    "    + Phòng thủ sớm trước các chuỗi nguy hiểm của người chơi.\n",
    "- Khi depth bị giới hạn, heuristic giúp AI vẫn đưa ra quyết định hợp lý thay vì đánh ngẫu nhiên.\n",
    "\n",
    "-> Sự kết hợp giữa **Minimax + Heuristic + Alpha-Beta** giúp AI duy trì chất lượng chơi ổn định ngay cả khi không thể tìm kiếm đến trạng thái kết thúc.\n",
    "\n",
    "#### **4. Đánh giá tổng thể**\n",
    "Từ các kết quả thực nghiệm có thể rút ra các nhận xét chính sau:\n",
    "- Alpha-Beta pruning mang lại **cải thiện hiệu năng** rõ rệt, đặc biệt ở các độ sâu lớn.\n",
    "- Minimax không có Alpha-Beta chỉ phù hợp cho bài toán nhỏ hoặc depth thấp.\n",
    "- Heuristic giúp AI hoạt động hiệu quả trong các tình huống không thể tìm kiếm sâu.\n",
    "- Hệ thống AI đạt được sự cân bằng tốt giữa:\n",
    "  + Độ mạnh chiến thuật\n",
    "  + Thời gian phản hồi\n",
    "  + Khả năng mở rộng cho bàn cờ lớn hơn\n",
    "\n",
    "#### **5. Hạn chế và hướng phát triển**\n",
    "Hạn chế: \n",
    "- Thử nghiệm hiện tại chủ yếu tập trung vào bàn cờ 3x3\n",
    "- Heuristic còn đơn giản\n",
    "Hướng phát triển:\n",
    "- Mở rộng đánh giá nhiều hơn ở bàn cờ lớn hơn \n",
    "- Nghiên cứu, cải thiện thêm chiến thuật phức tập để cải tiến Heuristic\n",
    "\n",
    "### **Kết luận**:\n",
    "Kết quả thực nghiệm cho thấy Alpha-Beta pruning là yếu tố then chốt giúp thuật toán Minimax đạt hiệu năng thực tế, đồng thời heuristic đóng vai trò quan trọng trong việc duy trì chất lượng quyết định khi giới hạn độ sâu tìm kiếm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cập nhật phân công, khối lượng công việc\n",
    "<!-- công việc của các thành viên, tỷ lệ đóng góp của các thành viên -->\n",
    "#### Phân công công việc:\n",
    "- Hải Minh: Xử lý logic trò chơi và thiết kế cải tiến Heuristic\n",
    "- Nguyên: Thuật toán Minimax + Alpha-Beta \n",
    "- Dũng: Phụ trách giao diện và tương tác người dùng\n",
    "- Đăng Minh: Phụ trách kiểm thử, đánh giá và báo cáo\n",
    "\n",
    "#### Tỷ lệ đóng góp:\n",
    "- Hải Minh:25%\n",
    "- Nguyên:25%\n",
    "- Dũng:25%\n",
    "- Đăng Minh: 25%\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
